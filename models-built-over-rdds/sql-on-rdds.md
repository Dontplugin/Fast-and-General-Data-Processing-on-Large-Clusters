# 3.3 Shark: SQL on RDDs

Shark:RDDs 上的 SQL
我们拿 Shark 系统作为在 RDDs 上实现高级的存储和处理技术的例子。Shark 在并行数据库
的大量研究领域中表现良好，并且还提供容错能力和复杂分析的能力，而这正是传统数据库所
不具备的。

# 3.3.1 Motivation

现在的数据分析面临着几个挑战。首先，数据量正在急剧增加，这也使得将计算任务分发
到计算机集群中的不同机器上，然后这些机器并行执行任务成为一种需求。其次，这种分发增
加了错误和 straggler（慢任务）的发生概率，并且使得并行数据库设计变得更加复杂。第三，
现在数据分析的复杂度和以前已经不一样了：现在的数据分析采用了先进的统计分析方法，比
如说机器学习算法，这种方法在汇总和分析能力上要远远超过传统企业所采取的数据仓库系统。
最后，尽管数据的规模和复杂度在不断增加，用户却仍然希望查询能够以交互速度执行。
为了解决这个“大数据”问题，探索的方向分成两条主线。第一条主线，考虑到 MapReduce 
[36]及其各种泛化版本[61, 27]提供了一个细粒度的适合大型集群的容错模型，在这种模型中，
失败的或者运行很慢的节点上的任务最终都一定能在其他的节点上再执行。MapReduce 本身也
非常泛化：它已经被证明能够表达许多统计和学习算法[31]。它同样也能支持非结构化的数据
和"schema-on-read.”但是，MapReduce 引擎缺少许多使数据库高效运行的特性，所以会表现
出几十秒到几小时的高延迟。即使是对于那些已经针对 SQL 查询显著优化过 MapReduce 的系统，
比如说谷歌的 Tenzing [27]，又或者是在每个节点上将 MapReduce 和传统数据库整合，比如说
HadoopDB [1]，最小的延迟也达到了 10 秒。因此，使用 MapReduce 的方法基本上不可能实现交
互速度的查询[84]，所以即使是谷歌自己也正在开发适用于此类负载的新引擎[75, 95]。
相反，大部分的 MPP 分析数据库(比如说， Vertica, Greenplum, Teradata)和几个新的为
MapReduce 环境建立的低延迟引擎(比如说,，Google F1 [95], Impala [60]) 采用了一种更粗
粒度的恢复模型，在这种模型中，如果一个机器失败了，整个查询必须要重新提交。这种粗粒
度的模型很适合执行短查询，因为重新提交段短询的代价比较低，但是对于长查询，这种模型
面临着几个重大挑战[1]。此外，这些系统缺少丰富的分析函数，比如说机器学习和图算法，而
这些函数在MapReduce下是很容易实现的。使用UDFs实现这些函数的确是一种可能可行的途径，
但是这些算法通常复杂度比较高，这会加剧对错误和 straggler（慢任务）恢复的需求。所以，
大多数的企业倾向于结合其他系统和 MPP 数据库去处理复杂的分析。
我们相信，要实现一种更加高效的大数据分析环境，处理系统需要同时支持高效的 SQL 和
复杂分析运算，还要能够为上述两种运算提供细粒度的恢复模型。我们提出了一个能够满足这
些需求的新系统，称之为 Shark。
Shark 使用 RDD 模型来执行大部分的计算，这些计算是在内存中完成的，与此同时，Shark
还提供一个细粒度的容错模型。对于大规模的分析来说，在内存中进行运算正在变得越来越重
要，这可以从以下两个方面来解释。第一，许多复杂的分析函数是迭代的，比如说机器学习和
图算法。第二，即使传统 SQL 仓库的工作负载也表现出很强的时间和空间局部性，这是因为最
近的表数据和小维度表数据经常频繁地被读取。在 Facebook 的 Hive 数据仓库和 Microsoft 的
Bing 分析集群上做的一项研究显示，两个系统中超过 95%的查询可以仅仅使用 64 GB/节点作为
高速缓存就能完成，尽管这两个系统管理的总数据量都已经超过 100PB[7]。
但是，为了高效的运行 SQL，我们也必须扩展 RDD 的执行模型，这也引出了几个传统分析数
据库中的概念以及一些新的概念。首先，为了高效地存储和处理关系数据，我们实现了在内存
中按列压缩存储数据的技术。这种方式与一般存储记录的方式相比，能够减小数据规模，处理
时间也能减少到原来的 1/5。第二，为了优化基于数据特征的 SQL 查询（即使在分析函数和 UDFs
存在的情况下），我们使用局部 DAG 执行(PDE)来扩展 Spark。在一个查询序列开始执行之后，
Spark 可以基于观测到的统计数据，选择一个更好的连接策略或者更合适的并发度，从而实现
重新优化正在运行中的查询序列。第三，我们利用在传统的 MapReduce 系统中不存在而在 Spark
引擎中存在的其他特性，比如说控制数据划分。
我们实现的 Shark 和 Apache 的 Hive 是兼容的[104]，支持 Hive 的所有 SQL 语句和 UDFs，
并且不经任何修改就可以在 Hive 数据仓库上使用。Spark 通过引进复杂分析函数增强了 SQL，
这些复杂分析函数使用 Spark 的 Java，Scala 和 Python API 来实现。在单个执行计划中，这些
函数可以和 SQL 组合在一起，从而为两种类型的处理提供内存数据共享和快速数据恢复的能力。
实验显示同时使用 RDD 和上面提到的所有优化，在 SQL 查询方面，Spark 的速度可以达到
Hive 的 100 倍，在运行迭代机器学习算法方面，Spark 的速度可以达到 Hadoop 的 100 倍，并且
可以在几秒钟内从查询错误中恢复。在Pavlo等人使用的与MapReduce比较的基准测试中，Shark
的速度可以和MPP数据库相媲美[84]，但是Shark还能提供细粒度的恢复模型和复杂分析特性，
这真是那些系统所欠缺的。






