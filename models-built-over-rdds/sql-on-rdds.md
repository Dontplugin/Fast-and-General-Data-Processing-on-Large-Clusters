# 3.3 `Shark`: `RDDs` 上的 `SQL`

我们拿 `Shark` 系统作为在 `RDDs` 上实现高级的存储和处理技术的例子。`Shark` 在并行数据库的大量研究领域中表现良好，并且还提供容错能力和复杂分析的能力，而这些正是传统数据库所缺少的。

# 3.3.1 动机

现在的数据分析面临着几个挑战。首先，数据量正在急剧增加，这引发了在数以百计的商业机器中的集群上扩展的需求。其次，这种规模增加了错误和 `straggler`（慢任务）的出现概率，并且使得并行数据库的设计变得更加复杂。
第三，数据分析的复杂度也已大大增加：现在的数据分析采用了先进的统计分析方法，比如说机器学习算法，这种方法在汇总和分析能力上要远远超过传统企业的数据仓库系统。
最后，尽管数据的规模和复杂度在不断增加，用户却仍然希望查询能够以交互速度执行。

为了解决这个“大数据”问题，探索的方向分成两条主线。第一条主线，考虑到 `MapReduce`【36】 及其各种泛化版本【61, 27】提供了一个适合大型集群的细粒度容错的模型，在这种模型中，
失败的或者运行很慢的节点上的任务最终都一定能在其他的节点上重新执行。`MapReduce`本身也非常泛化：它已经被证明能够表达许多统计和学习算法【31】。它同样也能容易地支持非结构化的数据
和"`schema-on-read`”。但是， `MapReduce`引擎缺少许多使数据库高效运行的特性，所以会表现出几十秒到几小时的高延迟。即使是对于那些已经针对 `SQL` 查询显著优化过 `MapReduce` 的系统，
比如说谷歌的 `Tenzing` 【27】，又或者是在每个节点上将`MapReduce`和传统数据库整合，比如说`HadoopDB` 【1】，最小的延迟也达到了 10 秒。因此，`MapReduce`的方法基本上不可能实现交
互速度的查询【84】，所以即使是谷歌自己也正在开发适用于此类负载的新引擎【75, 95】。

相反，大部分的 `MPP` 分析数据库(比如说， `Vertica`, `Greenplum`, `Teradata`)和几个新的为`MapReduce` 环境建立的低延迟引擎(比如说,，`Google F1` 【95】, `Impala` 【60】) 采用了一种更粗
粒度的恢复模型，在这种模型中，如果一个机器失败了整个查询必须要重新提交。这种模型很适合短查询，因为重新提交段短查询的代价比较低，但是随着集群的扩展【1】这种模型
面临着对于长查询的几个重大挑战【1】。此外，这些系统缺少丰富的在`MapReduce` 下是很容易实现的分析函数，比如说机器学习和图算法。使用`UDFs`实现这些函数的确是一种也许可行的途径，
但是这些算法通常花费比较高，这会加剧对长查询的错误和 `straggler`（慢任务）恢复的需求。所以，
大多数的企业倾向于结合其他系统和 `MPP` 数据库去处理复杂的分析。

我们相信，要实现一种更加高效的大数据分析环境，处理系统需要同时支持高效的 `SQL` 和复杂分析，还要能够为上述两种运算提供细粒度的恢复机制。我们提出了一个能够满足这
些需求的新系统，称之为 `Shark`。

`Shark` 使用 `RDD` 模型在内存中执行大部分的计算，与此同时，`Shark` 还提供一个细粒度的容错机制。对于大规模的分析来说，在内存中进行运算正在愈发重
要，我们从以下两个方面来解释。第一，许多复杂分析的函数是迭代的，比如说机器学习和图算法。第二，即使传统 `SQL` 仓库的工作负载也表现出很强的时间和空间局部性，这是因为最
近的事实表数据和小维度表数据经常频繁地被读取。在 `Facebook` 的 `Hive` 数据仓库和 `Microsoft` 的`Bing` 分析集群上做的一项研究显示，两个系统中超过 95%的查询可以仅仅使用 64 `GB`/节点作为
缓存就能完成，尽管每个系统管理的总数据量都已经超过 100`PB`【7】。

但是，为了高效的运行 `SQL`，我们也必须扩展 `RDD` 的执行模型，这也引出了传统的分析数据库以及一些新型数据库的几个概念。首先，为了高效地存储和处理关系型数据，我们实现了在内存
中按列存储和压缩数据的技术。这种方式能够减小数据规模，也能把处理时间缩减到原来的 1/5。第二，为了优化基于数据特征的 `SQL` 查询（即使存在分析函数和 `UDFs`），
我们使用局部 `DAG` 执行(`PDE`)来扩展 `Spark`。在一个`DAG` 任务运行了前几个阶段之后，`Spark` 可以基于观测到的统计数据，选择一个更好的连接策略或者更合适的并发度，从而能够重新优化正在运行的查询。
第三，我们利用传统的 `MapReduce` 系统中不具有而`Spark`引擎具有的其他特性，比如说控制数据分区。

我们实现的 `Shark` 和 `Apache` 的 `Hive` 是兼容的【104】，支持 `Hive` 的所有 `SQL` 语句和 `UDFs`，并且可以不经任何修改就在 `Hive` 数据仓库上执行。它通过使用 `Spark` 的 `Java`，`Scala` 和 `Python　API`
，引进`Spark` 的复杂分析函数从而加强了 `SQL`。在单个执行计划中，这些函数可以和 `SQL` 组合在一起，从而为两种类型的处理提供内存中的数据共享和快速数据恢复的能力。

实验显示同时使用 `RDD` 和上面提到的优化方法，在 `SQL` 查询方面，`Spark` 的速度可以达到`Hive` 的 100 倍；在运行迭代的机器学习算法方面，`Spark` 的速度可以达到 `Hadoop` 的 100 倍，并且
可以在几秒钟内从查询错误中恢复。在`Pavlo`等人使用的与`MapReduce`比较的基准测试中，`Shark`的速度可以和`MPP`数据库相媲美【84】，但是它还能提供细粒度的恢复机制和复杂分析特性，
这正是那些系统所缺乏的。






