# 1.2　弹性分布式数据集（`RDDs`）

为了解决这个问题，我们来介绍一种新的抽象概念，弹性分布式数据集（`RDDs`），它形成了一种简单扩展的`MapReduce`模型。`RDDs`的观点是：尽管`MapReduce`不适合的那些
工作负载（比如迭代、交互和流式查询）起初看起来非常的不同，但是他们都需要一个共同的功能，这是`MapReduce`所缺乏的：高效的并行式计算阶段之间的数据共享。
拥有高效的数据共享抽象和类似于`MapReduce`的操作，所有的这些工作负载就可以有效率的运行，并且在当前的专业系统里得到关键性的优化。`RDDs`用一种既高效又可以容错的方式
为广泛的并行计算提供了这种抽象。

尤其是，集群以往的容错处理模型比如`MapReduce`和`Dryad`，把计算任务转化为一个有向无环图`DAG`的任务集。从而就能够仅仅回滚`DAG`的一部分，来高效地实现故障恢复。然而
这些模型并没有提供除了复制的文件系统之外的存储抽象，导致跨网络的数据复制增加了大量的成本。相反地，`RDDs`是一个避免复制的可容错的分布式内存抽象。每一个`RDD`记住了由构建它的
操作而形成的图形，类似于批量计算模型，因此可以高效的重新计算那些由于故障引起的丢失数据。只要这些构建`RDDs`的操作是相对粗粒度的，比如适用于多个数据元素的单个操作，那么这种技术
会比跨网络的数据复制更有效率。`RDDs`很适用于如今广泛的数据并行算法和处理模型，他们都把每个操作应用于多个单元。

然而看起来可能很奇怪，仅仅增加数据共享就大大了提高了`MapReduce`的通用性，我们从下面几个角度探讨一下原因。　
首先，从可表达性角度来看，`RDDs`能够模仿任何一种分布式系统，并且非常高效，只需要这个系统能够容忍一些网络延迟。这是因为一旦使用快速的数据共享来扩展，`MapReduce`就可以模仿
整体同步计算模型（`BSP`）【108】的并行计算，它的主要缺点是每个`MapReduce`步骤的延迟。以经验看来，在我们的`Spark`系统，这可以低至50–100毫秒。
其次，从系统角度来看，`RDDs`并不像平常的`MapReduce`，给应用程序足够的控制来优化大多数集群计算（尤其是，网络和存储`I/O`）的瓶颈资源。因为这些资源掌控执行时间，仅仅控制它们
（比如通过控制数据布局）就常常足以比得上那些基于相同资源的专业系统的性能。

在探讨之外，我们的经验表明我们可以借助`RDDs`实现新的编程模型，以及如今在使用中的众多专业模型。它们的性能与那些提供丰富的容错特性和支持组合的专业系统的是一致的。