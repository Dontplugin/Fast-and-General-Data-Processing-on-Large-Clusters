> 描述`RDD`通用性的一个与模拟方法完全独立的方法是系统方法：在大部分的集群计算中瓶颈资源是什么？`RDD`是否能够有效地处理它们？在大部分的集群应用中，最明显的瓶颈是通讯和存储。
我们将展示`RDD`的分区和本地化特征使应用程序有足够的能力来对这些资源模拟通用的优化，从而使系统达到专业系统相似的性能。

# 瓶颈资源

虽然集群应用程序是多种多样的，但是它们都受到相同的底层硬件特性的限制。当前的数据中心有非常深的存储层次，这将限制大部分的应用程序。例如一个典型的数据中心可能有一下硬件特性：

- 每个节点拥有`50GB/s`左右内存带宽的本地内存以及多个磁盘-在`HADOOP`集群【80】中通常是12到24个。这意味着，假设有20个`100MB/s`的磁盘，本地存储带宽大约为`2GB/s`。

- 每个节点都有一个`10Gbps`(`1.3GB/s`) 的网络输出带宽，大约比内存带宽小40倍，比它的磁盘总带宽小2倍。

- `20-40`台机器节点组成机架，机架间的带宽为`20-40Gbps`，这比机架内部的网络性能要低10倍。

给定的这些特性，许多应用最关心的性能指标是网络的配置和通信。幸运的是，`RDD`为这提供了便利:其接口在运行时将计算运行在离数据最近的节点上，就像`MapReduce`的`Map`任务；
`RDD`提供了数据分区和共享。不同于`MapReduce`中的数据共享，总是隐式地需要经过网络传输，`RDD`不会造成网络流量，除非用户显示的调用跨节点的操作或者对数据集设置检查点。

从这个角度看，如果大部分的应用都有网络带宽限制，那么一个节点（例如，数据结构或`CPU`开销）的本地效率的影响将小于网络通信的效率的影响。根据我们的经验，
很多`Spark`应用都有带宽限制，特别是数据可以放进内存中时。当数据不能完全放进内存中时，应用程序会受`I/O`限制，在调度中，数据的本地化是造成`I/O`限制最重要的因素。
受CPU限制的应用程序更容易完全执行（许多应用在`MapReduce`上也能做得很好）。就像在上一章节的讨论中，`RDD`明显增加成本的地方就是网络延迟，但是我们在`Spark`上的工作表明，
这种延迟对很多应用来说足够小，甚至小到足够支持数据流。