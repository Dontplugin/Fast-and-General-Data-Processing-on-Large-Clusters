`D-Streams`通过将计算构造为一组*短的*，*无状态的*，*确定性的*任务代替连续的、有状态的操作来避免传统流处理的问题。然后通过容错的数据结构（`RDD`）来将状态保持在内存中，用于重新计算状态。
将计算分解成短任务并暴露其细粒度的依赖性并允许像并行恢复和推测（`speculate`）这样强大的恢复技术。除了容错，`D-Stream`还模型提供了其他好处，比如与批处理相结合。

![4.2](../images/4.2.png "Spark Streaming")

图4.2是`Spark`流系统的高级概述。`Spark Streaming` 把输入数据流分成批，并将它们存储在`Spark` 内存中，然后生成`Spark`作业来处理每个批次数据。

# 计算模型

我们把流计算看作在一小段时间范围内的一系列确定性的批计算。对于每个时间范围的数据，在集群中存储成一个可靠的数据集。一旦时间范围的数据准备好，这些数据可以通过确定的并行操作，如`map`、`reduce`、`group by`，去
产生新的数据集，这个新的数据集表示输出数据或者中间状态。对于前面的情况，结果可以以分布式的方式推送到一个外部系统。在后面的情况中，中间状态可以通过弹性分布式数据集（RDDs）的高效的存储，
这样可以避免使用`lineage`进行恢复而产生的冗余。该状态数据集可以与下一批输入数据一起处理，以产生一个新的数据集来更新中间状态。图 4.1.b展示了我们的模型。
