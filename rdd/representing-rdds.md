# 2.4　`RDDs`表示

把`RDDs`作为抽象使用而面临的挑战之一是如何去选取一个可以在大量的`transform`之间追踪到其血统图的表现形式。理想情况下，
一个实施了`RDDs`的系统应该尽可能丰富地提供各种变换操作（如表 2.2 中那些），并可以允许用户随意地进行组合。我们提出了一种基于图形的`RDDs`表现形式，可以
实现上述目标。我们已经在`Spark`中使用它来提供各种`transform`操作，而无需为每个`transform`的调度增加特殊的逻辑。这极大地简化了系统的设计。

简而言之，我们通过一个可以提供5种信息的通用接口来表现每个`RDD`：一组分区，数据集的原子集合；一组指向父`RDDs`的依赖关系；一个基于父`RDD`的数据集的计算函数；
和关于分区策略和数据布置的元数据。例如，表现一个`HDFS`文件的`RDD`一个对每个文件块的分区，并且知道每个文件块在哪台机器。同时，在这个`RDD`上的一个`map`任务的
结果具有相同的分区，当计算其元素时，将`map`函数应用于父`RDD`的数据。我们在表 2.3 中对这个接口做了总结。

在设计这个接口时，最有趣的问题是怎么表现`RDDs`之间的依赖关系。我们发现把依赖关系分成两种类型是合理而且有用的：窄依赖：每个父`RDD`的分区都至多被一个子`RDD`的分区使
用；宽依赖：多个子`RDD`的分区依赖同一个父`RDD`的分区。例如，`map`操作是一种窄依赖，而`join` 操作是一种宽依赖（除非父`RDD`已经基于 Hash 策略被分区过了）。
图 2.4 中展示了一些其他例子。

这种区别从两个方面来说是有用的。首先，窄依赖允许在单个集群节点上流水线式执行，这个节点可以计算所有父分区。例如，可以逐个元素依次地执行`filter` 和`map` 操作。
相比之下，宽依赖需要所有的父`RDD`数据是可用的，并且数据已经通过类`MapReduce` 的操作进行`shuffle`。其次，在窄依赖中，节点失败后的恢复更加高效。因为只有丢失的父分区需
要重新计算，并且它们可以并行地在不同节点上重新计算。而在宽依赖的血统图中，单个失败的节点可能导致一个`RDD`的所有先祖`RDD`中的一些分区丢失，导致全部计算需要重新执行。

这种`RDDs`的通用接口使得在`Spark` 中用不到 20 行的代码来实现了大多数的`transform`操作。事实上，即使是`Spark` 的新用户也能实现新的`transform`操作（如：抽样和各种类型的`join`）
而不必了解调度的细节。下面是一些`RDD`实现的概略图。

# `HDFS`文件：
在我们的例子中，输入`RDD`是`HDFS`文件。对于这些`RDD`，`partitions` 返回文件中每个文件块的分区（包含文件块在每个分区对象中的偏移量），`preferredLocations` 提供文件块所在的节点，
而`iterator` 读取这些文件块。

# `map`：
在任何一个`RDD`上调用`map` 操作将返回一个`MappedRDD` 对象。这个对象与其父对象具有相同的分区以及首选地点（`preferredLocations`），但在其迭代方法（`iterator` ）中，
把传递给`map`的函数应用到父对象记录。

# `union`：
在两个`RDD`上调用`union`操作将返回一个`RDD`，它的分区为它们的父`RDD`的分区`union`的结果。每个子分区都是通过在一个父分区上的窄依赖计算出来的。

# `sample`：
抽样类似于映射。不同之处是`RDD`会为每一个分区存储一个生成随机数的种子来对确定如何对父记录进行抽样。

# `join`：
连接两个`RDD`可能会产生两个窄依赖和两个宽依赖（如果两个`RDD`都是基于相同的`Hash`/范围分区策略），或一个混合（如果一个父`RDD`具有某种划分策略而另一个不具有）。
无论哪种情况，输出`RDD`都具有一个分区策略（要么继承于父`RDD`，要么是一个默认的`Hash`分区策略）。




